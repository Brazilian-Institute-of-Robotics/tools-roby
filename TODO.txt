= TODO

== Refactoring
* remote_id => network_id
* incremental_dump? => dump_reference?
* fix Roby::Control and Roby.control. Everything should be accessible from the
  same object. In a more general way, clean up the mess in globally used
  methods of Roby
* don't allow to change any event or task relations if the task is not incldued
  in a plan. This would finally fix problems related to logging and other stuff
  like the possibility of having tasks hanging around because they have never
  been removed from any plan.
* have a thread-safe handling of transactions. This requires a few things:
  - separate relation graphs: have one relation graph per plan object. The
    global constants would then be only numeric IDS (or symbols, whatever), and
    the various methods would get the relation graph from the object's plan.
    Note that it requires that all objects are always included in a plan (check
    the previous todo point)
  - stop using method forwarding, which is not the good way to do that.
    Instead, do as for distributed: update the task status in the transaction
    thread. Need to define a notion of "transaction thread" and how messages
    can get propagated there, though.

== Core
* dynamic parameters. State prediction in both plan and transaction context:
  allow to predict the effect of changing the value of dynamic parameters in
  transaction context.

* when predicates like happened? are called in a propagation context, and
  we don't know the result yet (happened? = false), register a continuation and
  its dependency on the event. Include this continuation in the event set and
  sort it accordingly. 

* in #replace, use Hierarchy#fullfilled_events to check that
  all needed events are provided. If some are missing, use define_event to try
  to add a new one dynamically

* when replacing an event generator, what to do with its handlers ?
  - either we discard them, because some handlers are used in a specific way
  - either we apply them on the new task
  - unfortunately there is no good answer... Both are useful and it is
    difficult (if not impossible) to know what to do. Having no solution for
    this problem reduces the usefulness of event handlers greatly.

* Need to tag relations with a name so that we can find what is what (kind of
  'roles'). For instance, in PlanningLoop, we would tag the seeds (i.e. the
  planned tasks) with a certain name which would allow to add any child without
  the loop code noticing

* add a multiplicity parameter for hierarchy relations which tells
  how many child task of a given kind are expected by the parent task. Add a
  'realized_by' transition for that. For instance, in case of
  Pom::Localization, we can tell that the task expects at least one
  Pom::Estimator. If the last estimator breaks, we can repair the plan online
  by adding a transition.

* we NEED plan merging: if we reuse a task which is already running, it should
  be transparent for the new process: this new task tree will call start!, but
  the task is running.  Moreover, if it is synchronizing on the start event, it
  should appear "as if" the event has been emitted

* Check the capability we have to put every application block in transaction
  context. This would allow for instance to discard **all** plan modification
  done by an exception handler (or plan command, event handler, you get my
  drift) if an exception is raised. I think it would be a worthy feature [This
  can't be done because of the transaction creation cost]

* Kill local tasks that are in force_gc even if they have parents, if their
  parents are remote tasks

* rename Roby::TaskModelTag::argument into 'arguments' (beware of name clash
  with the accessor)

* Fix transaction proxying. Better use the same kind of model than in dRoby:
  create slightly modified tasks of the same model than the proxied event, do
  not proxy task events

* Find a way to remove the "return unless proxying?" in top of proxy_code. It sucks

* fix handling of execution agents: we should re-spawn the execution agents
  only if there is an execution agent model on the task model. We currently use
  respawn on the execution agent instance.  The problem lies in, for instance,
  ConnectionTask which are respawned for all pending remote tasks.
  ConnectionTask should never be created because of the exected_by relation.

== Planning
* fix memory leak regarding planning loops: for now, make_loop creates a new
  planning method each time make_loop is called. The problem is that the
  created method should actually be local to the planner object, not the
  planner model (we are doing the latter right now).

== Distributed
* extension of communication to really have a multi-robot system. It is for now
  too much peer-to-peer
  - a pDB should always send the messages about objects it owns. For now, we
    check two things: that the involved objects are owned and that the message
    comes from the inside (we never forward a message coming from outside).
    There is a synchronization problem here:

	A sends a message M about a joint ab object to B
	B does not send the message to C
	but B can send other messages to C, including the /consequences/ of the M message

	Result: C knows about the consequences of M, but not about M itself.

    The solution is to mark all messages with an UID, and forward new messages
    when we decode them (in PeerServer#demux)
  - make sure unknown models are properly handled in 3-peers scenario. In
    particular, the following situation should work

	peer 1 and 2 know about a SpecificModel task model
	peer 3 does not

    If 1 sees tasks of 2 *through* the plan of 3, and if these tasks are of the
    SpecificModel model, then they should be instances of the SpecificModel
    class 

* There is a race condition when removing objects: if a peer A is building a
  transaction involving tasks from a peer B, and if the peer B removes the
  tasks, then there is a race condition between the time B sends the
  transaction and the time it processes the remove_object update from A. The
  net effect is that when the transaction sibling is created, some tasks it
  includes do not exist anymore.  It is more general, since the same problem
  exists when wrapping tasks in a transaction for instance.

  I don't think we should really fix the race condition per se. We should in
  general check if the object has not been removed when A processes updates
  from B and have some ways to feedback B from A.

== UI
* log snapshot: build a set of logging messages which represent the current
  state of the plan. Useful for display (it would allow to seek a lot faster)
  and for runtime display of the plan state (send the snapshot on connection)

 vim: tw=100
